---
title: "Modeling Lyrics"
format: html
---

```{python}
from sklearn.feature_extraction.text import CountVectorizer
import lda
import pandas as pd
import numpy as np
import requests
from transformers import pipeline
from joblib import load, dump
```


# Loading the Dataset 

```{python}
cleaned_df = pd.read_csv('final_dataset.csv')
cleaned_df
```


# Dropping the Stopwords and cleaning the data

```{python}
cleaned_df['lyrics_cleaned'] = cleaned_df['lyrics'].str.lower()
stopwords = requests.get('https://raw.githubusercontent.com/stopwords-iso/stopwords-en/refs/heads/master/stopwords-en.txt')

stopwords = stopwords.text.split('\n')

random_words = ['huh', 'em', 'di', 'da', 'somethin', 'ooh', 'uh', 'ha', 'hey', 'woah', 'yeah', '']

[stopwords.append(x) for x in random_words]

stopword_pattern = r'\b(?:{})\b'.format('|'.join(stopwords))

cleaned_df['lyrics_cleaned'] = cleaned_df['lyrics_cleaned'].str.replace(stopword_pattern, '', regex=True)
cleaned_df
```


# Fitting the data in a LDA Topic Model and calculating the probability of each songs fit in each topic

```
vectorizer = CountVectorizer()

X = vectorizer.fit_transform(cleaned_df['lyrics_cleaned'])

vocab = vectorizer.get_feature_names_out()

model = lda.LDA(n_topics=9, n_iter=500, random_state=13)

model.fit(X)

dump({
        'vectorizer': vectorizer,
        'X': X,
        'vocab': vocab,
        'model': model,
        'cleaned_lyrics_column': cleaned_df['lyrics_cleaned']
        }, 
    'ly_dump_topic.joblib')

vectorizer = CountVectorizer()

X = vectorizer.fit_transform(cleaned_df['lyrics_cleaned'])

vocab = vectorizer.get_feature_names_out()

model = lda.LDA(n_topics=9, n_iter=500, random_state=13)

model.fit(X)

topic_word = model.topic_word_

n_top_words = 50

top_words = []

for i, topic_dist in enumerate(topic_word):
  topic_words = np.array(vocab)[np.argsort(topic_dist)][:-n_top_words:-1]
  top_words.append(' '.join(topic_words))
  print('Topic {}: {}'.format(i, ' '.join(topic_words)))

doc_topic = model.doc_topic_

dump({
        'vectorizer': vectorizer,
        'X': X,
        'vocab': vocab,
        'model': model,
        'cleaned_lyrics_column': cleaned_df['lyrics_cleaned'],
        'topic_word': topic_word,
        'top_words': top_words,
        'doc_topic': doc_topic}, 
    'ly_dump_topic.joblib')
```

```
Topic 0: york hold lights feel time rains floor waitin babe called wrong looked silence baby bright phone honey beat night blind told innocent middle promises friend crowd stars left sun stare bedroom girls flashback real dream coming caught head standing lord heart day boy lover town bed wearing eyes body

Topic 1: red girl wanna gotta lost night blue lucky walk boy bye alright street met nights feels head lose time burning hit wonderland cool city heart game sky dancing delicate feeling taylor fun eyes worse guess song cornelia hope honestly reputation fall loving dark cried losing messed missing change favorite

Topic 2: baby bad blood grow feel smile time fly belong wanna fuck fall kiss feeling fine cut eyes sparks darling light jump mmm simple pick lights shine hand stay deep moment rain bless mad phone drop hurt waiting whisper solve heart sign pieces thinking tired chasing hide heartbeat hallway track

Topic 3: live time wait list white afraid follow god wild style leave lights girl vow meet lovers pain worth hear life insane fight game daydream single speak heard eyes screaming door drive eye bring treacherous hope kissed pretty mind reckless bout faith flames tight pretenders wrong straight learned stand shined

Topic 4: gonna shake hate break play fake baby friends mind nice people comin honey fallin real revenge players life rings learn toys busy saint touch sayin sick actress hear heartbreak dancin romantic fast trust moves hot laughed foolish lie goin haters stealing grace god feet block dirty walkin polish hurts

Topic 5: stay time woods trouble mad daylight remember finally hard wanna love clean december walked people hand goodbye talk night bet shame funny hold throw leave months lying water fall daughter late freedom flew grown start stand pouring change easy careless hope realized lock haze times breathe gonna rain careful

Topic 6: love beautiful time life leave loved hands bad dancin dark mind save magic feel london baby smile walk kiss breath watch watched burn rain wrong tied coming left breathe figured deep break fly daddy wishing feelin fighting romeo laughin friends tragic usin crazy thinkin girls lord eyes screaming day

Topic 7: remember night talk starlight forget dreams day hair lips karma bout dancing dream wind standin town stairs window time sweet friends lost rare die wildest door song days kitchen sacred street push prayer house change party red cheeks laugh cruel ground sky moved drive paper nice runnin car swear

Topic 8: dress car story dance night tonight happy summer town gonna meet fight sad getaway love eyes fearless head waiting sing hand gorgeous met lot late wonderin crowded killin starts hallelujah hands win white nothin feel enchanted wide twist spend wanna fate day lead silence conversation horse lonely question screamin
```

# Adding the modeling data to the dataframe and cleaning 

```{python}
loaded_data = load('ly_dump_topic.joblib')
doc_topic = loaded_data['doc_topic']

cleaned_df['top_topic'] = np.argmax(doc_topic, axis=1) 

cleaned_df['top_prob'] = [max(doc_topic[x]) for x in range(len(doc_topic))]

cleaned_df['top_topic'].value_counts()

for i in range(9):
    cleaned_df[f'topic_{i}'] = doc_topic[:, i]

topic_rename_map = {
    'topic_0': 'Honey and Daylight',
    'topic_1': 'My Heart in Your Palms', 
    'topic_2': 'Ghosts of You',
    'topic_3': 'Rain or Shine',
    'topic_4': 'Unapologetically ME!',
    'topic_5': 'Beginningâ€™s Butterflies',
    'topic_6': 'Hearts on the Edge',
    'topic_7': 'POV',
    'topic_8': 'Echoes of Betrayal'
}

cleaned_df = cleaned_df.rename(columns=topic_rename_map)
cleaned_df
```


# Checking the grouping of the model

```{python}
group = cleaned_df.groupby('top_topic')

topic_counts = group['song_name'].count()
print("Number of songs per topic:")
print(topic_counts)
print(cleaned_df.columns)
```


# Sentiment Analysis

```{python}
sentiment_analysis = pipeline("sentiment-analysis")

def sentiment_results(text):
    sent_result = sentiment_analysis(text)
    label = sent_result[0]['label']
    score = sent_result[0]['score']
    return [label, score]

cleaned_df['sent'] = cleaned_df['lyrics'].apply(lambda x: sentiment_results(str(x)[:511]))

cleaned_df[['sentiment_label', 'sentiment_score']] = cleaned_df['sent'].apply(pd.Series)

cleaned_df['sentiment_score'] = cleaned_df['sentiment_score'].round(4)
```


# Extracting CSV

```{python}
cleaned_df.to_csv('modeled_dataset.csv', index=False)
```